cat("\n\nAnd the t value at that point is:\t", i,"\n\n")
break
} else {
print("P(t) is still too small for the rows to be equal")
}
# Update p.initial for the next iteration
p.initial = p.new
}
# Define p.initial
p.initial = trans.mat[[1]]
i = 0
while (i < 100) {
i = i + 1
p.new = p.initial %*% q.3
# Check if the row values are equal
if (check_mat(p.new, p.initial)) {
print(p.new)
cat("\n\nAnd the t value at that point is:\t", i,"\n\n")
break
} else {
print("P(t) is still too small for the rows to be equal")
}
# Update p.initial for the next iteration
p.initial = p.new
}
stead_probs(q.3)
Re(stead_probs(q.3))
matrix(c( 0.19736842,0.21052632,0.02631579,0.56578947), nrow = 1, byrow = TRUE) * q.3
matrix(c( 0.19736842,0.21052632,0.02631579,0.56578947), nrow = 1, byrow = TRUE) %*% q.3
pi.mat = matrix(c( 0.19736842,0.21052632,0.02631579,0.56578947), nrow = 1, byrow = TRUE)
output.3 = pi.mat %*% q.3
output.3
knitr::opts_chunk$set(echo = TRUE)
library(markovchain)
hold.Time = matrix(c(0.1, 0.2, 2), nrow = 1, byrow = TRUE)
nm.1 = c("trainee", "Junior DS", "Senior DS")
colnames(hold.Time) = nm.1
hold.Time
library(DiagrammeR)
grViz("digraph{
graph [rankdir = 'LR'];
node [format = 'helvetica', shape = 'circle'];
# the nodes
tab1 [label = 'trainee', fillcolor = '#35fe00', style = filled];
tab2 [label = 'Junior Data Scientist', fillcolor = '#fe3500', style = filled];
tab3 [label = 'Senior Data Scientist', fillcolor = '#0035fe', style = filled];
# Arch
tab1 -> tab2 [label = '2/3'];
tab1 -> tab3 [label = '1/3'];
tab2 -> tab1 [label = '2/5'];
tab2 -> tab3 [label = '3/5'];
tab3 -> tab1 [label = '1/4'];
tab3 -> tab2 [label = '3/4'];
}")
q.1= matrix(c(-3, 2, 1, 4, -10, 6, 5, 15, -20), nrow = 3, byrow = TRUE)
colnames(q.1) = nm.1
rownames(q.1) = nm.1
q.1
library(matlib)
stead_probs = function(q.1){
eig = eigen(t(q.1))
# extract eigen value for each eigen vector
pi = eig$vectors[, which.min(abs(eig$values))]
# normalize
pi = pi/sum(pi)
return(pi)
}
steady_prob.1 = stead_probs(q.1)
steady_prob.1
steady = matrix(c(10/17, 5/17, 2/17), nrow = 1, byrow = TRUE)
colnames(steady) = nm.1
cat("The steady state probability is:\n\n")
steady
q.2 = matrix(c(-3, 2, 0, 1, 0, -2, 1/2, 3/2, 1, 1, -4, 2, 1, 0, 0, -1), nrow = 4, byrow = TRUE)
hold.time.2 = matrix(-diag(q.2), nrow = 1, byrow = TRUE)
nm.2 = c("1", "2", "3", "4")
colnames(hold.time.2) = nm.2
cat("The expected sojourn time is: \n\n")
hold.time.2
grViz("digraph{
graph [rankdir = 'LR'];
node [format = 'helvetica', shape = 'circle'];
# the nodes
tab1 [label = '1', fillcolor = '#35fe00', style = filled];
tab2 [label = '2', fillcolor = '#fe3500', style = filled];
tab3 [label = '3', fillcolor = '#0035fe', style = filled];
tab4 [label = '4', fillcolor = '#cb35fe', style = filled];
# Arch
tab1 -> tab2 [label = '2/3'];
tab1 -> tab4 [label = '1/3'];
tab2 -> tab3 [label = '1/4'];
tab2 -> tab4 [label = '3/4'];
tab3 -> tab1 [label = '1/4'];
tab3 -> tab2 [label = '1/4'];
tab3 -> tab4 [label = '1/2'];
tab4 -> tab1 [label = '1'];
}")
steady_prob.2 = stead_probs(q.2)
steady_prob.2
a = 1
b = 1.5
c = 2
d = -1
round((a * Re(steady_prob.2[1])) + (b * Re(steady_prob.2[2])) + (c * Re(steady_prob.2[3])) + (d * Re(steady_prob.2[4])), 4) == 0
sum(Re(steady_prob.2))
cat("Long run mean fraction of time (unit time): \n \n")
long_mean_time = matrix(Re(steady_prob.2), nrow = 1, byrow = TRUE)
colnames(long_mean_time) = nm.2
long_mean_time
q.3 = matrix(c(-3, 2, 0, 1, 0, -2, 1/2, 3/2, 1, 1, -4, 2, 1, 0, 0, -1),nrow = 4, byrow = TRUE)
colnames(q.3) = rownames(q.3) = nm.2
q.3
states = q.3
t = seq(0, 1.5, 0.5)
library(expm)
prob.func = function(state, t){
P.t = expm(state * t)
return(P.t)
}
trans.mat= c()
for (i in 1:length(t)){
trans.mat[[i]] = prob.func(states, t[i])
}
trans.mat
check_mat = function(A, B){
b = 0
for (i in 1:nrow(A)){
if(all(all.equal(A[i,], B[i,]) == TRUE)){
b = b + 1
}else{
b = b - 1
}
}
return(b = nrow(A))
}
# Define p.initial
p.initial = trans.mat[[1]]
i = 0
while (i < 100) {
i = i + 1
p.new = p.initial %*% q.3
# Check if the row values are equal
if (check_mat(p.new, p.initial)) {
print(p.new)
cat("\n\nAnd the t value at that point is:\t", i,"\n\n")
break
} else {
print("P(t) is still too small for the rows to be equal")
}
# Update p.initial for the next iteration
p.initial = p.new
}
Re(stead_probs(q.3))
pi.mat = matrix(c( 0.19736842,0.21052632,0.02631579,0.56578947), nrow = 1, byrow = TRUE)
output.3 = pi.mat %*% q.3
output.3
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
content_creator <- read_excel("07 03 2024 Social Media Information.xlsx")
View(content_creator)
unique(content_creator$`Creative industry`)
industry_data = data.frame(national_id = content_creator$`National ID`,
industry = content_creator$`Creative industry`,
count = rep(1, nrow(content_creator)))
library(dplyr)
industry_data = industry_data %>% group_by(industry) %>% summarise(count = sum(count))
library(ggplot2)
ggplot(industry_data, aes(x = industry, y = count)) +
geom_bar(stat = "identity") +
labs(
title = "The main fields from the study",
x = "The creative industry",
y = "The number of individuals"
) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
knitr::opts_chunk$set(echo = TRUE)
library(arules)
data(mtcars)
mtcars_eclat = as(as.matrix(mtcars), "transactions")
freq_items = eclat(mtcars_eclat, parameter = list(supp = 0.1, maxlen = 5))
inspect(freq_items)
inspect(tail(freq_items, 5))
colnames(mtcars)
library(arules)
data2 = mtcars
# convert continuous to categories
data2$mpg = cut(data2$mpg, breaks = 3, labels = c("Low consumption", "Medium consumption", "High consumption"))
data2$hp = cut(data2$hp, breaks = 3, labels = c("Low HP", "Medium HP", "High HP"))
data2$qsec = cut(data2$qsec, breaks = 4, labels = c("very slow", "slow", "fast",  "very fast"))
data2$disp = cut(data2$disp, breaks = 3, labels = c("low displacement", "medium displacement", "high displacement"))
# convert to matrix
data3 = data.frame(mpg = data2$mpg,
hp = data2$hp,
qsec = data2$qsec,
disp = data2$disp)
data2_apriori = as(data3, "transactions")
apri_analysis_1 = apriori(data2_apriori, parameter = list(supp = 0.3, conf = 0.8, target = "rules"))
inspect(apri_analysis_1)
data4 = data2
data4 = as.data.frame(lapply(data4, as.factor))
data4_trans = as(data4, "transactions")
q3_rules = apriori(data4_trans, parameter = list(supp = 0.1, conf = 0.6, minlen = 2))
# recommend based on confidence
# check top 5 recommendations
inspect(head(q3_rules, sort = "confidence",n = 5))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), control = list(verbose = FALSE))
inspect(sort(data5_rules, by = "support"))
knitr::opts_chunk$set(echo = TRUE)
library(arules)
data(mtcars)
mtcars_eclat = as(as.matrix(mtcars), "transactions")
freq_items = eclat(mtcars_eclat, parameter = list(supp = 0.1, maxlen = 5))
inspect(freq_items)
inspect(tail(freq_items, 5))
colnames(mtcars)
library(arules)
data2 = mtcars
# convert continuous to categories
data2$mpg = cut(data2$mpg, breaks = 3, labels = c("Low consumption", "Medium consumption", "High consumption"))
data2$hp = cut(data2$hp, breaks = 3, labels = c("Low HP", "Medium HP", "High HP"))
data2$qsec = cut(data2$qsec, breaks = 4, labels = c("very slow", "slow", "fast",  "very fast"))
data2$disp = cut(data2$disp, breaks = 3, labels = c("low displacement", "medium displacement", "high displacement"))
# convert to matrix
data3 = data.frame(mpg = data2$mpg,
hp = data2$hp,
qsec = data2$qsec,
disp = data2$disp)
data2_apriori = as(data3, "transactions")
apri_analysis_1 = apriori(data2_apriori, parameter = list(supp = 0.3, conf = 0.8, target = "rules"))
inspect(apri_analysis_1)
data4 = data2
data4 = as.data.frame(lapply(data4, as.factor))
data4_trans = as(data4, "transactions")
q3_rules = apriori(data4_trans, parameter = list(supp = 0.1, conf = 0.6, minlen = 2))
# recommend based on confidence
# check top 5 recommendations
inspect(head(q3_rules, sort = "confidence",n = 5))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), control = list(verbose = FALSE))
inspect(head(sort(data5_rules, by = "support"), 5))
gear = apriori(mtcars_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs = "gear"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs = "gear"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), control = list(verbose = FALSE))
inspect(head(sort(gear, by = "support"), 5))
colnames(data6)
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear=4 && gear= 5"), control = list(verbose = FALSE))
gear = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear=4"), control = list(verbose = FALSE))
inspect(head(sort(gear, by = "support"), 5))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs = "high_hp = 1"), control = list(verbose = FALSE))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs="high_hp = 1"), control = list(verbose = FALSE))
knitr::opts_chunk$set(echo = TRUE)
library(arules)
data(mtcars)
mtcars_eclat = as(as.matrix(mtcars), "transactions")
freq_items = eclat(mtcars_eclat, parameter = list(supp = 0.1, maxlen = 5))
inspect(freq_items)
inspect(tail(freq_items, 5))
colnames(mtcars)
library(arules)
data2 = mtcars
# convert continuous to categories
data2$mpg = cut(data2$mpg, breaks = 3, labels = c("Low consumption", "Medium consumption", "High consumption"))
data2$hp = cut(data2$hp, breaks = 3, labels = c("Low HP", "Medium HP", "High HP"))
data2$qsec = cut(data2$qsec, breaks = 4, labels = c("very slow", "slow", "fast",  "very fast"))
data2$disp = cut(data2$disp, breaks = 3, labels = c("low displacement", "medium displacement", "high displacement"))
# convert to matrix
data3 = data.frame(mpg = data2$mpg,
hp = data2$hp,
qsec = data2$qsec,
disp = data2$disp)
data2_apriori = as(data3, "transactions")
apri_analysis_1 = apriori(data2_apriori, parameter = list(supp = 0.3, conf = 0.8, target = "rules"))
inspect(apri_analysis_1)
data4 = data2
data4 = as.data.frame(lapply(data4, as.factor))
data4_trans = as(data4, "transactions")
q3_rules = apriori(data4_trans, parameter = list(supp = 0.1, conf = 0.6, minlen = 2))
# recommend based on confidence
# check top 5 recommendations
inspect(head(q3_rules, sort = "confidence",n = 5))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs="high_hp = 1"), control = list(verbose = FALSE))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs="high_hp"), control = list(verbose = FALSE))
data5 = data4
data5$hp = mtcars$hp
data5$high_hp = as.factor(ifelse(data5$hp > quantile(mtcars$hp, 0.75), 1, 0))
data6 = data5[, c(c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12))]
data6 = as.data.frame(lapply(data6, as.factor))
data5_trans = as(data6, "transactions")
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), control = list(verbose = FALSE))
inspect(head(sort(data5_rules, by = "support"), 5))
gear5 = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(rhs = "gear=5"), control = list(verbose = FALSE))
inspect(head(sort(gear5, by = "support"), 5))
data5_rules = apriori(data5_trans, parameter = list(supp = 0.05, conf = 0.05), appearance = list(lhs = "high_hp=1"), control = list(verbose = FALSE))
inspect(head(sort(data5_rules, by = "support"), 5))
setwd("C:/Users/ADMIN/Documents/SEM 2 2024/STA4020 Design and Analysis of Experiments")
equal_reps = data.frame(replicate = seq(1,4),
treat_A = c(23, 36, 31, 33),
treat_B = c(42, 26, 47, 34),
treat_C = c(47, 43, 43, 39)
)
print("Equal Repetition")
equal_reps
unequal_reps = data.frame(replicate = seq(1, 5),
treat_A = c(2, 2.2, 1.8, 2.3, 1.7),
treat_B = c(1.7, 1.9, 1.5, NA, NA),
treat_C = c(2, 2.4, 2.7, 2.5, 2.4),
treat_D = c(2.1, 2.2, 2.2, 1.9, NA))
print("Unequal Repetition")
unequal_reps
ncol(equal_reps[-1])
sum(equal_reps[-1])
sum(c(23, 36, 31, 33, 42, 26, 47, 34, 47, 43, 43, 39))
equal_n = nrow(equal_reps) * ncol(equal_reps[-1])
equal_exp_total = sum(equal_reps[-1])
equal_corr_f = (equal_exp_total^ 2)/ equal_n
cat("The correction factor of equal replicates is:\n", equal_corr_f, "\n")
unequal_n = nrow(unequal_reps) * ncol(unequal_reps[-1])
unequal_exp_total = sum(unequal_reps[-1])
unequal_corr_f = (unequal_exp_total^ 2)/ unequal_n
cat("The correction factor of equal replicates is:\n", unequal_corr_f, "\n")
install.packages("dplyr")
install.packages("tidyr")
library(dplyr)
library(tidyr)
View(unequal_reps)
unequal_n =  sum(!is.na(unequal_reps[-1]))
unequal_exp_total = sum(unequal_reps[-1], na.rm = TRUE)
unequal_corr_f = (unequal_exp_total^ 2)/ unequal_n
cat("The correction factor of equal replicates is:\n", unequal_corr_f, "\n")
equal_tts = sum(equal_reps[-1]^ 2) - equal_corr_f
cat("The equal replicates total sum of squares is:\n", equal_tts, "\n")
unequal_tts = sum(unequal_reps[-1]^ 2, na.rm = TRUE) - unequal_corr_f
cat("The equal replicates total sum of squares is:\n", unequal_tts, "\n")
equal_reps = data.frame(replicate = seq(1,4),
treat_A = c(23, 36, 31, 33),
treat_B = c(42, 26, 47, 34),
treat_C = c(47, 43, 43, 39)
)
print("Equal Repetition")
equal_reps
unequal_reps = data.frame(replicate = seq(1, 5),
treat_A = c(2, 2.2, 1.8, 2.3, 1.7),
treat_B = c(1.7, 1.9, 1.5, NA, NA),
treat_C = c(2, 2.4, 2.7, 2.5, 2.4),
treat_D = c(2.1, 2.2, 2.2, 1.9, NA))
print("Unequal Repetition")
unequal_reps
equal_n = nrow(equal_reps) * ncol(equal_reps[-1])
equal_exp_total = sum(equal_reps[-1])
equal_corr_f = (equal_exp_total^ 2)/ equal_n
cat("The correction factor of equal replicates is:\n", equal_corr_f, "\n")
library(dplyr)
library(tidyr)
unequal_n =  sum(!is.na(unequal_reps[-1]))
unequal_exp_total = sum(unequal_reps[-1], na.rm = TRUE)
unequal_corr_f = (unequal_exp_total^ 2)/ unequal_n
cat("The correction factor of equal replicates is:\n", unequal_corr_f, "\n")
equal_tss = sum(equal_reps[-1]^ 2) - equal_corr_f
cat("The equal replicates total sum of squares is:\n", equal_tss, "\n")
unequal_tss = sum(unequal_reps[-1]^ 2, na.rm = TRUE) - unequal_corr_f
cat("The unequal replicates total sum of squares is:\n", unequal_tss, "\n")
equal_tts = colSums(equal_reps[-1])
equal_ttss = sum(equal_tts^2)/ nrow(equal_reps) - equal_corr_f
cat("The equal replicates treatment sum of squares is:\n", equal_ttss, "\n")
unequal_tts = colSums(unequal_reps[-1], na.rm = T)
unequal_ttss = sum(unequal_tts^2)/ colSums(!is.na(unequal_reps)) - unequal_corr_f
cat("The equal replicates treatment sum of squares is:\n", unequal_ttss, "\n")
cat("The equal replicates error sum of squares is:\n", equal_tss - equal_ttss, "\n")
cat("The equal replicates error sum of squares is:\n", unequal_tss - unequal_ttss, "\n")
equal_long = equal_reps %>% gather(key = "treatment", value = "value", - replicate) # using every column except the replicate column
equal_long
anova_equal_reps = aov(value~treatment, data = equal_long)
summary(anova_equal_reps)
# there are na in the unequal replicate data
# using filter can help ~i hope
unequal_long = unequal_reps %>% gather(key = "treatment", value = "value", - replicate) %>% filter(!is.na(value)) # using every column except the replicate column
unequal_long
anova_unequal_reps = aov(value~treatment, data = unequal_long)
summary(anova_unequal_reps)
equal_pval = summary(anova_equal_reps)[[1]][["Pr(>F)"]][1]
unequal_pval = summary(anova_unequal_reps)[[1]][["Pr(>F)"]][1]
hypothesis_conclusion = function(sig_lev, pval, case){
cat("\nAt", pval, "% significance level:\n")
if(pval < sig_lev){
cat("for case", case, "Reject the null hypothesis.\n\tConclude that there is a statistically significance difference in the treatment means")
}else{
cat("for case", case, "Fail to reject the null hypothesis.\n\tConclude that there is no statistically significance difference in the treatment means")
}
}
equal_pval = summary(anova_equal_reps)[[1]][["Pr(>F)"]][1]
unequal_pval = summary(anova_unequal_reps)[[1]][["Pr(>F)"]][1]
hypothesis_conclusion = function(sig_lev, pval, case){
cat("\nAt", pval, "% significance level:\n")
if(pval < sig_lev){
cat("for case", case, "Reject the null hypothesis.\n\tConclude that there is a statistically significance difference in the treatment means")
}else{
cat("for case", case, "Fail to reject the null hypothesis.\n\tConclude that there is no statistically significance difference in the treatment means")
}
}
equal_reps = data.frame(replicate = seq(1,4),
treat_A = c(23, 36, 31, 33),
treat_B = c(42, 26, 47, 34),
treat_C = c(47, 43, 43, 39)
)
print("Equal Repetition")
equal_reps
unequal_reps = data.frame(replicate = seq(1, 5),
treat_A = c(2, 2.2, 1.8, 2.3, 1.7),
treat_B = c(1.7, 1.9, 1.5, NA, NA),
treat_C = c(2, 2.4, 2.7, 2.5, 2.4),
treat_D = c(2.1, 2.2, 2.2, 1.9, NA))
print("Unequal Repetition")
unequal_reps
equal_n = nrow(equal_reps) * ncol(equal_reps[-1])
equal_exp_total = sum(equal_reps[-1])
equal_corr_f = (equal_exp_total^ 2)/ equal_n
cat("The correction factor of equal replicates is:\n", equal_corr_f, "\n")
library(dplyr)
library(tidyr)
unequal_n =  sum(!is.na(unequal_reps[-1]))
unequal_exp_total = sum(unequal_reps[-1], na.rm = TRUE)
unequal_corr_f = (unequal_exp_total^ 2)/ unequal_n
cat("The correction factor of equal replicates is:\n", unequal_corr_f, "\n")
equal_tss = sum(equal_reps[-1]^ 2) - equal_corr_f
cat("The equal replicates total sum of squares is:\n", equal_tss, "\n")
unequal_tss = sum(unequal_reps[-1]^ 2, na.rm = TRUE) - unequal_corr_f
cat("The unequal replicates total sum of squares is:\n", unequal_tss, "\n")
equal_tts = colSums(equal_reps[-1])
equal_ttss = sum(equal_tts^2)/ nrow(equal_reps) - equal_corr_f
cat("The equal replicates treatment sum of squares is:\n", equal_ttss, "\n")
unequal_tts = colSums(unequal_reps[-1], na.rm = T)
unequal_ttss = sum(unequal_tts^2)/ colSums(!is.na(unequal_reps)) - unequal_corr_f
cat("The unequal replicates treatment sum of squares is:\n", unequal_ttss, "\n")
cat("The equal replicates error sum of squares is:\n", equal_tss - equal_ttss, "\n")
cat("The equal replicates error sum of squares is:\n", unequal_tss - unequal_ttss, "\n")
equal_long = equal_reps %>% gather(key = "treatment", value = "value", - replicate) # using every column except the replicate column
equal_long
anova_equal_reps = aov(value~treatment, data = equal_long)
summary(anova_equal_reps)
# there are na in the unequal replicate data
# using filter can help ~i hope
unequal_long = unequal_reps %>% gather(key = "treatment", value = "value", - replicate) %>% filter(!is.na(value)) # using every column except the replicate column
unequal_long
anova_unequal_reps = aov(value~treatment, data = unequal_long)
summary(anova_unequal_reps)
equal_pval = summary(anova_equal_reps)[[1]][["Pr(>F)"]][1]
unequal_pval = summary(anova_unequal_reps)[[1]][["Pr(>F)"]][1]
hypothesis_conclusion = function(sig_lev, pval, case){
cat("\nAt", pval, "% significance level:\n")
if(pval < sig_lev){
cat("for case", case,"at significance level", sig_lev, "Reject the null hypothesis.\n\tConclude that there is a statistically significance difference in the treatment means")
}else{
cat("for case", case,"at significance level", sig_lev, "Fail to reject the null hypothesis.\n\tConclude that there is no statistically significance difference in the treatment means")
}
}
hypothesis_conclusion(0.05, equal_pval, "equal replicates")
hypothesis_conclusion(0.1, equal_pval, "equal replicates")
hypothesis_conclusion(0.05, unequal_pval, "unequal replicates")
hypothesis_conclusion(0.1, unequal_pval, "unequal replicates")
equal_pval = summary(anova_equal_reps)[[1]][["Pr(>F)"]][1]
unequal_pval = summary(anova_unequal_reps)[[1]][["Pr(>F)"]][1]
hypothesis_conclusion = function(sig_lev, pval, case){
cat("\nAt", round(pval, 4), "% significance level:\n")
if(pval < sig_lev){
cat("for case", case,"at significance level", sig_lev, "Reject the null hypothesis.\n\tConclude that there is a statistically significance difference in the treatment means")
}else{
cat("for case", case,"at significance level", sig_lev, "Fail to reject the null hypothesis.\n\tConclude that there is no statistically significance difference in the treatment means")
}
}
hypothesis_conclusion(0.05, equal_pval, "equal replicates")
hypothesis_conclusion(0.1, equal_pval, "equal replicates")
hypothesis_conclusion(0.05, unequal_pval, "unequal replicates")
hypothesis_conclusion(0.1, unequal_pval, "unequal replicates")
